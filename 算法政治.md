# 算法政治 王中原

Governance by algorithm / Governance of algorithms

**分配政治（Distributive Politics）**

哈罗德·D·拉斯韦尔（Harold D. Lasswell）

# Governance by Algorithm

Governance by algorithm / Governance of algorithms

---

## 分配政治（Distributive Politics）

> 哈罗德·D·拉斯韦尔（Harold D. Lasswell）：“政治就是关于：谁获得什么、何时获得、如何获得。”
>
> Politics is about "who gets what, when, and how." (Lasswell, 1936)

分配政治（Distributive politics）通常指政府对公共物品与服务的分配与调配，包括财政拨付、福利发放、项目审批与资源倾斜等。

### 常见范畴
- 财政与预算：专项资金、基础设施投资、科研经费分配
- 公共服务：教育、医疗、住房保障与社会福利
- 政策工具：税收优惠、补贴、配额与豁免

---

## 算法的治理与算法治政

- 算法治理（Governance of algorithms）：针对算法的规则与监管，例如透明度、问责、审计与合规。
- 算法治政（Governance by algorithm）：政府或机构使用算法来辅助或自动化决策流程，例如资源分配、风险评估、执法与公共服务优化。

### 关键原则
- 透明可解释：可说明算法如何影响分配结果
- 公平与无偏：避免对特定群体的系统性歧视
- 责任与追责：明确数据与模型的责任边界
- 安全与隐私：保护个人信息与敏感数据

---

## 示例（分配政治与算法的结合）
- 医疗资源调度：基于需求、距离与紧急程度的算法优化救护车与床位分配
- 教育经费分配：按区域贫困指数与入学人数的模型分配专项资金
- 社会救助判定：结合收入、资产与风险指标的机器学习辅助审核（需强审计以防误拒）
- 城市基础设施：按拥堵热力与事故风险评估的道路维护优先级排序

---

## 技术要点（AI 生成）

### 模型与方法
- 评分与排序：逻辑回归、梯度提升树、学习排序（LambdaMART）
- 优化与调度：线性/整数规划、约束规划、启发式搜索与多目标优化
- 因果与公平：配对实验、因果森林、IV/DiD；公平约束（EO/DP/EOpp）

### 数据与指标
- 特征治理：来源、可用性、偏差检测（PSI、KS、Shapley）
- 评估指标：准确率/召回率、AUC、校准误差（ECE）、不平等度量（Theil、Gini）
- 稳健性：分布漂移（covariate/label shift）与鲁棒评估（stress test）

### 流水线与审计
- MLOps：数据版本、模型卡、审计日志、影子评估与灰度发布
- 解释性：特征重要性、局部解释（LIME/SHAP）、反事实实例
- 合规栅栏：输入约束、输出阈值与人工复核闸门（human-in-the-loop）

---

## 哲学与政治理论要点（AI 生成）

- 公平的多维概念：结果公平（outcome）、机会公平（opportunity）、流程公平（procedural）
- 正当性与授权：算法决策的民主合法性来源于可审计规则、公共参与与事后可申诉性
- 认识论问题：数据即世界的“切片”，统计规律不等同于规范正当；需区分预测与处置
- 价值冲突：效率与公平、隐私与可用性、短期绩效与长期韧性之间的权衡
- 责任分配：开发者、机构、算法与数据之间的责任边界与“问责可追踪性”
- 工具理性批判：算法是手段，不是目的；政策目标应先行，模型为目标服务而非反客为主

> 提示：以上“技术要点/哲学要点”为 AI 生成的学习笔记，供参考与讨论。

---

## 参考引文
- Lasswell, H. D. (1936). Politics: Who Gets What, When, How.
- 相关政策框架：算法透明、AI伦理治理与数据保护的国际与本地规范（如GDPR原则、公共部门算法使用指南等）。

---

## AI 生成补充（标注：AI 生成）
本节为 AI 生成内容，用于辅助学习与讨论，不构成权威政策文本。

### 定义与分类（AI 生成）
- 决策支持算法：用于评分、排序与预测的模型（例如线性模型、树模型与深度学习）
- 规则引擎：可审计的显式规则体系（如资格判定与阈值触发）
- 优化与调度：基于约束与目标的资源配置（如线性规划、整数规划与元启发式）

### 风险与缓解（AI 生成）
- 数据偏差：历史数据不均衡导致模型歧视；缓解措施包括重采样、偏差测试与公平约束
- 黑箱困境：难以解释的模型降低信任；采用可解释方法（特征重要性、反事实解释）与模型卡（Model Card）
- 目标漂移：长期运行中目标函数偏离公共利益；建立治理委员会与定期政策复盘
- 过度自动化：将裁量完全交给算法；设定“人机协同”与人工复核阈值

### 实践清单（AI 生成）
- 明确分配目标与衡量指标（公平、效率、可及性）
- 建立数据治理：来源记录、用途限制与合规审计
- 引入影响评估：上线前做算法影响评估（AIA）
- 设置申诉渠道：为被影响个体提供解释与复核路径
- 发布透明报告：定期公开模型更新与效果评估

> 注：以上补充为 AI 生成，供参考与讨论。

>好的算法体现在分配，监管，选举上
>算法作为技术，谈不上公平,最主要的正当性仍是“效率”
一种迷思考，妄想全靠算法来解决一切制度形体